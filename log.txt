episode:1, reward: -9.089462863111494, mean reward: -1.7, score: -201.8934829162613, epsilon: 0.893311454540539, total steps: 238
episode:2, reward: -425.89879416519204, mean reward: -425.9, score: -425.89879416519204, epsilon: 0.893283344627222, total steps: 239
episode:3, reward: -7.397841907689324, mean reward: -1.43, score: -201.42990523744444, epsilon: 0.8893292123971106, total steps: 380
episode:4, reward: -8.639223155759522, mean reward: -2.04, score: -201.81203381144013, epsilon: 0.886563991120744, total steps: 479
episode:5, reward: -417.5795238402217, mean reward: -417.58, score: -417.5795238402217, epsilon: 0.8865361061191259, total steps: 480
episode:6, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.8865082220469924, total steps: 481
episode:7, reward: -8.576092945110188, mean reward: -3.97, score: -202.3320784053768, epsilon: 0.8850873661392236, total steps: 532
episode:8, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.8850595303576179, total steps: 533
episode:9, reward: -16.224741813288862, mean reward: -3.38, score: -216.10756187192646, epsilon: 0.8832799688999915, total steps: 597
episode:10, reward: -12.56271470451265, mean reward: -1.67, score: -204.34907262600842, epsilon: 0.8798981779952454, total steps: 719
episode:11, reward: -417.32592432998194, mean reward: -417.33, score: -417.32592432998194, epsilon: 0.8798705151836951, total steps: 720
episode:12, reward: -11.400908850517297, mean reward: -2.56, score: -201.92652701318156, epsilon: 0.877688064315195, total steps: 799
episode:13, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.8776604751728728, total steps: 800
episode:14, reward: -425.8850599141468, mean reward: -425.89, score: -425.8850599141468, epsilon: 0.8776328869501733, total steps: 801
episode:15, reward: -5.029182169375311, mean reward: -1.88, score: -200.91538526560507, epsilon: 0.8746862542720298, total steps: 908
episode:16, reward: -13.00425621484547, mean reward: -2.85, score: -205.07464285450436, epsilon: 0.8727093804592516, total steps: 980
episode:17, reward: -5.659229719412441, mean reward: -3.36, score: -205.16803769153103, epsilon: 0.8710382376233049, total steps: 1041
episode:18, reward: -0.7908338580227339, mean reward: -6.07, score: -200.43544395322525, epsilon: 0.8701355921079695, total steps: 1074
episode:19, reward: -27.60908872852124, mean reward: -1.92, score: -222.866729968915, epsilon: 0.8669705242264952, total steps: 1190
episode:20, reward: -425.9008635039494, mean reward: -425.9, score: -425.9008635039494, epsilon: 0.8669432923295552, total steps: 1191
episode:21, reward: -100, mean reward: -1.23, score: -58.979756347271525, epsilon: 0.8656372281917653, total steps: 1239
episode:22, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.8656100407372856, total steps: 1240
episode:23, reward: -9.58144855442241, mean reward: -1.7, score: -204.14955882429015, epsilon: 0.8623541167635147, total steps: 1360
episode:24, reward: -10.916432783631503, mean reward: -3.2, score: -204.75867389959123, epsilon: 0.8606229418908475, total steps: 1424
episode:25, reward: -8.28159338151733, mean reward: -1.07, score: -205.248656881301, epsilon: 0.8554515212605335, total steps: 1616
episode:26, reward: -3.8209586810528005, mean reward: -3.97, score: -202.5975452009668, epsilon: 0.8540834168925885, total steps: 1667
episode:27, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.8540566145587334, total steps: 1668
episode:28, reward: -13.277369012280051, mean reward: -2.65, score: -206.46799794502283, epsilon: 0.8519687827184182, total steps: 1746
episode:29, reward: -6.99448724438581, mean reward: -1.77, score: -203.71870720564553, epsilon: 0.8489004537724256, total steps: 1861
episode:30, reward: -24.979611401878696, mean reward: -1.05, score: -202.3927788313994, epsilon: 0.843777357814605, total steps: 2054
episode:31, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.843750899010327, total steps: 2055
episode:32, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.8437244410879944, total steps: 2056
episode:33, reward: -7.965876881622594, mean reward: -2.24, score: -207.89744555458336, epsilon: 0.8412677052286393, total steps: 2149
episode:34, reward: -9.53000177628908, mean reward: -1.76, score: -200.8244212207881, epsilon: 0.8382665936720647, total steps: 2263
episode:35, reward: -4.576457087790869, mean reward: -1.8, score: -203.60260182793283, epsilon: 0.8353030410305594, total steps: 2376
episode:36, reward: -16.16209609750105, mean reward: -2.25, score: -200.48551161309348, epsilon: 0.8329767610303229, total steps: 2465
episode:37, reward: -12.842298987502364, mean reward: -5.98, score: -209.34905536432467, epsilon: 0.8320638207944762, total steps: 2500
episode:38, reward: -3.5188959273733857, mean reward: -3.4, score: -200.45313533023946, epsilon: 0.8305272733804562, total steps: 2559
episode:39, reward: -15.691402800745822, mean reward: -2.18, score: -202.7067982542776, epsilon: 0.8281113853940789, total steps: 2652
episode:40, reward: -8.241480885601067, mean reward: -2.7, score: -205.49276852135694, epsilon: 0.826142664650257, total steps: 2728
episode:41, reward: -18.241475828707518, mean reward: -1.34, score: -203.15549540884348, epsilon: 0.8222201539011905, total steps: 2880
episode:42, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.8221944136584003, total steps: 2881
episode:43, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.8221686742736037, total steps: 2882
episode:44, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.8221429357467724, total steps: 2883
episode:45, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.8221171980778779, total steps: 2884
episode:46, reward: -337.1059414289055, mean reward: -337.11, score: -337.1059414289055, epsilon: 0.822091461266891, total steps: 2885
episode:47, reward: -6.451579617958023, mean reward: -3.84, score: -203.29092054856275, epsilon: 0.8207286372010382, total steps: 2938
episode:48, reward: -13.89027579834425, mean reward: -1.5, score: -207.5419804623144, epsilon: 0.8171914272899868, total steps: 3076
episode:49, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.8171658546686231, total steps: 3077
episode:50, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.817140282899666, total steps: 3078
episode:51, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.817114711983087, total steps: 3079
episode:52, reward: -336.7160407442065, mean reward: -336.72, score: -336.7160407442065, epsilon: 0.8170891419188577, total steps: 3080
episode:53, reward: -8.064447396721162, mean reward: -2.85, score: -204.89793135524013, epsilon: 0.8152503354286676, total steps: 3152
episode:54, reward: -19.385517571412393, mean reward: -2.14, score: -200.8142912694285, epsilon: 0.8128563036527792, total steps: 3246
episode:55, reward: -15.4591946463135, mean reward: -4.93, score: -211.9844258187009, epsilon: 0.8117636595328941, total steps: 3289
episode:56, reward: -16.383392843708993, mean reward: -2.15, score: -211.00623885534617, epsilon: 0.8092792915886423, total steps: 3387
episode:57, reward: -5.6959764138114855, mean reward: -1.69, score: -201.16826435195267, epsilon: 0.806273449260562, total steps: 3506
episode:58, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.806248240565734, total steps: 3507
episode:59, reward: -6.765847199234968, mean reward: -2.5, score: -205.1342151848512, epsilon: 0.8041839844766996, total steps: 3589
episode:60, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.8041588454295369, total steps: 3590
episode:61, reward: -4.055100175406986, mean reward: -2.84, score: -201.73753558245036, epsilon: 0.8023761132272331, total steps: 3661
episode:62, reward: -10.07287130934552, mean reward: -1.82, score: -209.42273676424435, epsilon: 0.7994975256110627, total steps: 3776
episode:63, reward: -11.058018412978852, mean reward: -2.55, score: -206.29727490518536, epsilon: 0.7974766117533257, total steps: 3857
episode:64, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.7974516962815275, total steps: 3858
episode:65, reward: -332.175443523926, mean reward: -332.18, score: -332.175443523926, epsilon: 0.7974267816402311, total steps: 3859
episode:66, reward: -6.370922096688613, mean reward: -1.76, score: -204.5921889348105, epsilon: 0.7945423116536978, total steps: 3975
episode:67, reward: -16.166023960738503, mean reward: -2.39, score: -205.31471499233797, epsilon: 0.7924110133474074, total steps: 4061
episode:68, reward: -14.46830066498297, mean reward: -1.02, score: -200.5185395294544, epsilon: 0.7875764049777474, total steps: 4257
episode:69, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.7875518195073415, total steps: 4258
episode:70, reward: -29.481003602726627, mean reward: -2.48, score: -217.86758201370137, epsilon: 0.7853915041816235, total steps: 4346
episode:71, reward: -25.16179175981508, mean reward: -1.19, score: -205.45002724907675, epsilon: 0.781187323059867, total steps: 4518
episode:72, reward: -336.72732120457505, mean reward: -336.73, score: -336.72732120457505, epsilon: 0.781162950555309, total steps: 4519
episode:73, reward: -8.40935216463694, mean reward: -1.77, score: -200.04935924624144, epsilon: 0.778414083724108, total steps: 4632
episode:74, reward: -19.93550832631527, mean reward: -2.09, score: -217.72680831606723, epsilon: 0.7758932868063861, total steps: 4736
episode:75, reward: -5.92544246974963, mean reward: -2.94, score: -202.5943588023541, epsilon: 0.7742256507633304, total steps: 4805
episode:76, reward: -16.175545931384203, mean reward: -1.99, score: -202.886629132969, epsilon: 0.7717674648348655, total steps: 4907
episode:77, reward: -9.903429574394158, mean reward: -1.78, score: -204.7285530742114, epsilon: 0.7690059857694066, total steps: 5022
episode:78, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.7689820193026575, total steps: 5023
episode:79, reward: -25.376304375444942, mean reward: -2.42, score: -219.90672919482827, epsilon: 0.7668044115522282, total steps: 5114
episode:80, reward: -425.8885445728446, mean reward: -425.89, score: -425.8885445728446, epsilon: 0.7667805184700635, total steps: 5115
episode:81, reward: -13.805057311870389, mean reward: -2.73, score: -207.47823004108852, epsilon: 0.7649669726179298, total steps: 5191
episode:82, reward: -13.818619919886396, mean reward: -3.64, score: -211.29286940075656, epsilon: 0.7635860384706795, total steps: 5249
episode:83, reward: -13.842507226559013, mean reward: -3.73, score: -205.3985159321877, epsilon: 0.7622789958886097, total steps: 5304
episode:84, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.7622552536511196, total steps: 5305
episode:85, reward: -425.88977790702774, mean reward: -425.89, score: -425.88977790702774, epsilon: 0.7622315122050242, total steps: 5306
episode:86, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.7622077715502972, total steps: 5307
episode:87, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.762184031686912, total steps: 5308
episode:88, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.7621602926148425, total steps: 5309
episode:89, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.7621365543340622, total steps: 5310
episode:90, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.7621128168445448, total steps: 5311
episode:91, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.7620890801462638, total steps: 5312
episode:92, reward: -15.289972065161525, mean reward: -2.98, score: -208.3099047364115, epsilon: 0.7604294759171583, total steps: 5382
episode:93, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.7604057953293064, total steps: 5383
episode:94, reward: -425.8952909273193, mean reward: -425.9, score: -425.8952909273193, epsilon: 0.7603821155307943, total steps: 5384
episode:95, reward: -13.919316246875974, mean reward: -2.01, score: -201.0888329051647, epsilon: 0.7580181173315772, total steps: 5484
episode:96, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.7579945171210051, total steps: 5485
episode:97, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.7579709176970937, total steps: 5486
episode:98, reward: -336.56703372950255, mean reward: -336.57, score: -336.56703372950255, epsilon: 0.7579473190598166, total steps: 5487
episode:99, reward: -16.374663706298136, mean reward: -2.35, score: -214.1600367181805, epsilon: 0.7558031325189967, total steps: 5578
episode:100, reward: -3.8299085842974776, mean reward: -1.23, score: -201.80624046681953, epsilon: 0.7519552691370702, total steps: 5742
episode:101, reward: -425.90437235570766, mean reward: -425.9, score: -425.90437235570766, epsilon: 0.7519318710180699, total steps: 5743
episode:102, reward: -6.613831174142447, mean reward: -1.81, score: -202.43716419136683, epsilon: 0.7493162109697327, total steps: 5855
episode:103, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.7492929008178717, total steps: 5856
episode:104, reward: -425.870851974071, mean reward: -425.87, score: -425.870851974071, epsilon: 0.7492695914430028, total steps: 5857
episode:105, reward: -23.62630579214581, mean reward: -1.45, score: -202.1358161163338, epsilon: 0.7460371366390791, total steps: 5996
episode:106, reward: -3.7538792118610265, mean reward: -1.08, score: -202.30683820776173, epsilon: 0.7417119991700327, total steps: 6183
episode:107, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.7416889424876738, total steps: 6184
episode:108, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.7416658865738583, total steps: 6185
episode:109, reward: -15.781850681482727, mean reward: -1.32, score: -212.50443460637982, epsilon: 0.737963888894817, total steps: 6346
episode:110, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.7379409571473851, total steps: 6347
episode:111, reward: -19.400221455704997, mean reward: -2.03, score: -212.78750547338893, epsilon: 0.7355373725241187, total steps: 6452
episode:112, reward: -17.82847674093278, mean reward: -2.38, score: -200.0621527580608, epsilon: 0.7336205526811534, total steps: 6536
episode:113, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.7335977657091824, total steps: 6537
episode:114, reward: -332.294887037308, mean reward: -332.29, score: -332.294887037308, epsilon: 0.7335749794967644, total steps: 6538
episode:115, reward: -9.596599898791911, mean reward: -2.15, score: -202.3113008317378, epsilon: 0.7314364633193087, total steps: 6632
episode:116, reward: -10.86521828489469, mean reward: -3.86, score: -200.8386993697723, epsilon: 0.7302563298606898, total steps: 6684
episode:117, reward: -8.849979987963929, mean reward: -1.66, score: -201.25825944124963, epsilon: 0.7275181550281645, total steps: 6805
episode:118, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.7274955714660584, total steps: 6806
episode:119, reward: -14.876600605416353, mean reward: -1.55, score: -203.4219618788685, epsilon: 0.7245436239134018, total steps: 6937
episode:120, reward: -332.3262129985102, mean reward: -332.33, score: -332.3262129985102, epsilon: 0.7245211395006802, total steps: 6938
episode:121, reward: -10.561986657176519, mean reward: -4.09, score: -208.67352484852807, epsilon: 0.7233754276944899, total steps: 6989
episode:122, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.7233529822209934, total steps: 6990
episode:123, reward: -12.436125321819201, mean reward: -5.06, score: -202.39099622366592, epsilon: 0.7224557765147557, total steps: 7030
episode:124, reward: -23.645675644241834, mean reward: -1.54, score: -223.57133583939319, epsilon: 0.7192134156125417, total steps: 7175
episode:125, reward: -332.4690507242075, mean reward: -332.47, score: -332.4690507242075, epsilon: 0.719191108870469, total steps: 7176
episode:126, reward: -7.267153811897008, mean reward: -2.92, score: -201.40769986343415, epsilon: 0.7176537379743217, total steps: 7245
episode:127, reward: -7.979543364716479, mean reward: -2.73, score: -202.19039174156532, epsilon: 0.7160088882359953, total steps: 7319
episode:128, reward: -11.877125378425514, mean reward: -4.93, score: -207.23038817020887, epsilon: 0.715077128176694, total steps: 7361
episode:129, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.7150549593085712, total steps: 7362
episode:130, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.7150327911793986, total steps: 7363
episode:131, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.715010623789151, total steps: 7364
episode:132, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.7149884571378045, total steps: 7365
episode:133, reward: -19.974707602154172, mean reward: -2.14, score: -211.93783896717, epsilon: 0.7127976121117341, total steps: 7464
episode:134, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.7127755192262138, total steps: 7465
episode:135, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.7127534270771109, total steps: 7466
episode:136, reward: -15.047232758654722, mean reward: -3.77, score: -203.79639961852584, epsilon: 0.7115615439250175, total steps: 7520
episode:137, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.7115394922410833, total steps: 7521
episode:138, reward: -6.711652724285858, mean reward: -1.73, score: -202.7873071308256, epsilon: 0.7089645126952432, total steps: 7638
episode:139, reward: -9.875480968943906, mean reward: -5.49, score: -203.30549909140834, epsilon: 0.7081522907693967, total steps: 7675
episode:140, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.7081303527253404, total steps: 7676
episode:141, reward: -12.131561697516066, mean reward: -2.77, score: -202.3796509979265, epsilon: 0.706530849052414, total steps: 7749
episode:142, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.7065089650555143, total steps: 7750
episode:143, reward: -3.2352299737287122, mean reward: -2.13, score: -202.3620036210358, epsilon: 0.7044333081907262, total steps: 7845
episode:144, reward: -11.154615287583866, mean reward: -3.71, score: -207.82443147786483, epsilon: 0.7032128388079156, total steps: 7901
episode:145, reward: -7.55370370459862, mean reward: -1.69, score: -202.7095893547869, epsilon: 0.7006052061947529, total steps: 8021
episode:146, reward: -13.927151736979708, mean reward: -2.17, score: -208.29658526867757, epsilon: 0.6985265970832542, total steps: 8117
episode:147, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.6985049798903066, total steps: 8118
episode:148, reward: -6.496335193425221, mean reward: -0.96, score: -205.84170311173884, epsilon: 0.6938739751226225, total steps: 8333
episode:149, reward: -332.311880093517, mean reward: -332.31, score: -332.311880093517, epsilon: 0.6938525130144889, total steps: 8334
episode:150, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.693831051621747, total steps: 8335
episode:151, reward: -417.0573839845157, mean reward: -417.06, score: -417.0573839845157, epsilon: 0.6938095909443729, total steps: 8336
episode:152, reward: -20.755120776926585, mean reward: -1.05, score: -212.1983678994647, epsilon: 0.689489168112068, total steps: 8538
episode:153, reward: -331.99197889989586, mean reward: -331.99, score: -331.99197889989586, epsilon: 0.6894678521617321, total steps: 8539
episode:154, reward: -11.381839362719838, mean reward: -5.58, score: -200.8062332927715, epsilon: 0.6887009509718801, total steps: 8575
episode:155, reward: -15.541724753164605, mean reward: -1.13, score: -200.20946972031533, epsilon: 0.6849437101207798, total steps: 8752
episode:156, reward: -336.60668774729197, mean reward: -336.61, score: -336.60668774729197, epsilon: 0.6849225456831851, total steps: 8753
episode:157, reward: -27.062465951364057, mean reward: -1.24, score: -226.7692893040246, epsilon: 0.6810613069058391, total steps: 8936
episode:158, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.681040271879528, total steps: 8937
episode:159, reward: -2.5510951269158704, mean reward: -1.98, score: -201.4685372093361, epsilon: 0.6788983782376857, total steps: 9039
episode:160, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.6788774153077953, total steps: 9040
episode:161, reward: -24.32644044015174, mean reward: -0.99, score: -204.55506998694577, epsilon: 0.6745739159799254, total steps: 9246
episode:162, reward: -425.89637276955716, mean reward: -425.9, score: -425.89637276955716, epsilon: 0.6745530971963745, total steps: 9247
episode:163, reward: -16.863389868434453, mean reward: -1.15, score: -202.29663414455592, epsilon: 0.6708997792370874, total steps: 9423
episode:164, reward: -8.410090018489763, mean reward: -3.31, score: -205.4835276427836, epsilon: 0.669617911412999, total steps: 9485
episode:165, reward: -19.242228705615226, mean reward: -2.38, score: -212.2357298799036, epsilon: 0.6677824355778146, total steps: 9574
episode:166, reward: -13.201845413645842, mean reward: -3.32, score: -202.5472073944939, epsilon: 0.6665275541872399, total steps: 9635
episode:167, reward: -5.923489535052453, mean reward: -3.11, score: -201.94678742398025, epsilon: 0.6651931905690952, total steps: 9700
episode:168, reward: -4.590750538637968, mean reward: -1.36, score: -202.5556433228308, epsilon: 0.6621453062340759, total steps: 9849
episode:169, reward: -425.8748312995975, mean reward: -425.87, score: -425.8748312995975, epsilon: 0.6621249017306117, total steps: 9850
episode:170, reward: -18.571046152699687, mean reward: -1.45, score: -203.22455986329743, epsilon: 0.659274973859657, total steps: 9990
episode:171, reward: -7.613613504767709, mean reward: -2.24, score: -201.74368463745435, epsilon: 0.6574498879357782, total steps: 10080
episode:172, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.6574296399436487, total steps: 10081
episode:173, reward: -4.778820421661891, mean reward: -3.3, score: -201.0867998587546, epsilon: 0.656195787850499, total steps: 10142
episode:174, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.6561755816610091, total steps: 10143
episode:175, reward: -9.543696816986872, mean reward: -3.09, score: -204.00954739834458, epsilon: 0.6548434612510944, total steps: 10209
episode:176, reward: -5.72821049039023, mean reward: -1.33, score: -202.7281128465118, epsilon: 0.6517666122327778, total steps: 10362
episode:177, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.6517465536800144, total steps: 10363
episode:178, reward: -8.871259115869073, mean reward: -4.63, score: -203.58406980733167, epsilon: 0.6508646389635006, total steps: 10407
episode:179, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.6508446104760117, total steps: 10408
episode:180, reward: -332.6171007643136, mean reward: -332.62, score: -332.6171007643136, epsilon: 0.6508245826561281, total steps: 10409
episode:181, reward: -15.36135567490667, mean reward: -3.53, score: -211.7430965750584, epsilon: 0.6496241343392821, total steps: 10469
episode:182, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.6496041472012583, total steps: 10470
episode:183, reward: -417.4097450621941, mean reward: -417.41, score: -417.4097450621941, epsilon: 0.6495841607294613, total steps: 10471
episode:184, reward: -7.841421790770532, mean reward: -2.2, score: -206.65465954868628, epsilon: 0.647708403912835, total steps: 10565
episode:185, reward: -14.931563356922613, mean reward: -1.58, score: -211.7546406238333, epsilon: 0.6450445933145244, total steps: 10699
episode:186, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.6450247588253237, total steps: 10700
episode:187, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.6450049249972618, total steps: 10701
episode:188, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.6449850918303166, total steps: 10702
episode:189, reward: -417.4173796693548, mean reward: -417.42, score: -417.4173796693548, epsilon: 0.6449652593244658, total steps: 10703
episode:190, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.6449454274796876, total steps: 10704
episode:191, reward: -11.44312604175599, mean reward: -2.42, score: -202.99497497284332, epsilon: 0.643281910293636, total steps: 10788
episode:192, reward: -100, mean reward: -1.31, score: -56.13165641414399, epsilon: 0.6424321486968418, total steps: 10831
episode:193, reward: -18.545825793329644, mean reward: -2.32, score: -212.99329441264928, epsilon: 0.6406181396763151, total steps: 10923
episode:194, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.6405984527331101, total steps: 10924
episode:195, reward: -336.7252688453858, mean reward: -336.73, score: -336.7252688453858, epsilon: 0.6405787664461255, total steps: 10925
episode:196, reward: -5.3155720501791235, mean reward: -2.24, score: -204.16126095620305, epsilon: 0.6387900584332334, total steps: 11016
episode:197, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.6387704324250543, total steps: 11017
episode:198, reward: -6.008916915766573, mean reward: -0.92, score: -203.0995460401067, epsilon: 0.6344685753419177, total steps: 11237
episode:199, reward: -332.4656815938709, mean reward: -332.47, score: -332.4656815938709, epsilon: 0.634449093380774, total steps: 11238
episode:200, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.6344296120690183, total steps: 11239
episode:201, reward: -20.602298917115583, mean reward: -1.05, score: -214.8570180569327, epsilon: 0.630449623501088, total steps: 11444
episode:202, reward: -14.064690734850785, mean reward: -3.09, score: -213.1280007548756, epsilon: 0.6291161234799111, total steps: 11513
episode:203, reward: -16.90098720334554, mean reward: -2.01, score: -204.58164696977238, epsilon: 0.6271504721608988, total steps: 11615
episode:204, reward: -4.812138064100186, mean reward: -1.26, score: -202.51423550136877, epsilon: 0.6240613943996969, total steps: 11776
episode:205, reward: -6.090787311541069, mean reward: -7.03, score: -203.80998657872155, epsilon: 0.6235067365129472, total steps: 11805
episode:206, reward: -17.068829212398448, mean reward: -1.0, score: -201.48198880373562, epsilon: 0.6196770850368327, total steps: 12006
episode:207, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.6196580961171485, total steps: 12007
episode:208, reward: -7.485200075426867, mean reward: -3.57, score: -207.3140146996044, epsilon: 0.6185578210732464, total steps: 12065
episode:209, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.6185388694617392, total steps: 12066
episode:210, reward: -417.54064099033604, mean reward: -417.54, score: -417.54064099033604, epsilon: 0.6185199184819419, total steps: 12067
episode:211, reward: -10.07034230082366, mean reward: -2.21, score: -201.54105059627693, epsilon: 0.6167980209274517, total steps: 12158
episode:212, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.6167791279749717, total steps: 12159
episode:213, reward: -18.83691351682272, mean reward: -1.32, score: -205.5203773915377, epsilon: 0.6138395260982812, total steps: 12315
episode:214, reward: -7.105193125587518, mean reward: -3.13, score: -200.55415296767887, epsilon: 0.6126379505788675, total steps: 12379
episode:215, reward: -23.666099005169617, mean reward: -0.98, score: -210.29324284305122, epsilon: 0.6086201263332442, total steps: 12594
episode:216, reward: -9.190235326844483, mean reward: -1.22, score: -201.84947032913632, epsilon: 0.6055561492990269, total steps: 12759
episode:217, reward: -16.08999094740378, mean reward: -1.54, score: -202.82066184743678, epsilon: 0.6031170721468893, total steps: 12891
episode:218, reward: -13.772165481116739, mean reward: -2.53, score: -212.66256334104585, epsilon: 0.6015705105415455, total steps: 12975
episode:219, reward: -12.469922892733452, mean reward: -1.87, score: -200.54024261958986, epsilon: 0.5996067465148994, total steps: 13082
episode:220, reward: -4.9260990177677915, mean reward: -4.11, score: -201.19947841215856, epsilon: 0.5987097882109471, total steps: 13131
episode:221, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.5986914981895088, total steps: 13132
episode:222, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.5986732087777277, total steps: 13133
episode:223, reward: -15.054205008281194, mean reward: -1.23, score: -203.54085545580298, epsilon: 0.5956456011285346, total steps: 13299
episode:224, reward: -13.751983454849627, mean reward: -1.43, score: -202.76133408612603, epsilon: 0.5930689814271288, total steps: 13441
episode:225, reward: -425.51593744568765, mean reward: -425.52, score: -425.51593744568765, epsilon: 0.5930508794294496, total steps: 13442
episode:226, reward: -9.796837875105219, mean reward: -2.13, score: -200.25990497839993, epsilon: 0.5913519830015896, total steps: 13536
episode:227, reward: -3.5852997698747093, mean reward: -4.0, score: -200.18748431070512, epsilon: 0.5904504811568053, total steps: 13586
episode:228, reward: -18.453547311517976, mean reward: -2.55, score: -208.93342918869644, epsilon: 0.5889752668862704, total steps: 13668
episode:229, reward: -11.528699357138104, mean reward: -3.68, score: -202.3588864804635, epsilon: 0.5879880507882473, total steps: 13723
episode:230, reward: -16.555162696504063, mean reward: -2.18, score: -200.14150286602873, epsilon: 0.5863407479212234, total steps: 13815
episode:231, reward: -7.128555945501187, mean reward: -2.33, score: -204.98381330233443, epsilon: 0.5847697869298788, total steps: 13903
episode:232, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.5847519615674055, total steps: 13904
episode:233, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.584734136799101, total steps: 13905
episode:234, reward: -4.455889876528617, mean reward: -1.2, score: -201.10673056413933, epsilon: 0.5817479946348667, total steps: 14073
episode:235, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.5817302699971244, total steps: 14074
episode:236, reward: -8.625349512282266, mean reward: -1.38, score: -202.45692470831847, epsilon: 0.5791311646825338, total steps: 14221
episode:237, reward: -332.03496710329404, mean reward: -332.03, score: -332.03496710329404, epsilon: 0.5791135272710028, total steps: 14222
episode:238, reward: -7.766114036014491, mean reward: -2.52, score: -204.19302735986395, epsilon: 0.5776868476315921, total steps: 14303
episode:239, reward: -18.88967774382334, mean reward: -1.01, score: -206.65558508886528, epsilon: 0.5741107495809566, total steps: 14507
episode:240, reward: -13.571294617546119, mean reward: -2.23, score: -209.93390056687971, epsilon: 0.5724711060153269, total steps: 14601
episode:241, reward: -24.465158063790632, mean reward: -1.46, score: -209.41141732263603, epsilon: 0.5699865865522926, total steps: 14744
episode:242, reward: -426.2783624871847, mean reward: -426.28, score: -426.2783624871847, epsilon: 0.5699692539549523, total steps: 14745
episode:243, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.5699519219353558, total steps: 14746
episode:244, reward: -15.526940317567135, mean reward: -2.1, score: -204.05073084177334, epsilon: 0.5682734590317419, total steps: 14843
episode:245, reward: -9.98101859159512, mean reward: -5.45, score: -207.1968770756409, epsilon: 0.5676173949119624, total steps: 14881
episode:246, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.5676001412863606, total steps: 14882
episode:247, reward: -5.852164721270013, mean reward: -1.72, score: -203.0378549259977, epsilon: 0.5655682460775174, total steps: 15000
episode:248, reward: -25.343930028234485, mean reward: -1.69, score: -201.3473558398725, epsilon: 0.5635272094336344, total steps: 15119
episode:249, reward: -332.2734164783569, mean reward: -332.27, score: -332.2734164783569, epsilon: 0.5635100921452763, total steps: 15120
episode:250, reward: -16.64346186551637, mean reward: -1.82, score: -200.23359760750387, epsilon: 0.5616306695212034, total steps: 15230
episode:251, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.5616136154497888, total steps: 15231
episode:252, reward: -6.335946589843734, mean reward: -1.3, score: -202.55204191755502, epsilon: 0.5589601296916065, total steps: 15387
episode:253, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.5589431646367025, total steps: 15388
episode:254, reward: -13.221197557933106, mean reward: -1.47, score: -212.2805699635505, epsilon: 0.5565060911021087, total steps: 15532
episode:255, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.5564892078471277, total steps: 15533
episode:256, reward: -6.628514983442077, mean reward: -5.33, score: -202.35099871082122, epsilon: 0.5558480609959177, total steps: 15571
episode:257, reward: -15.090626207841563, mean reward: -1.29, score: -200.5628233870437, epsilon: 0.5532412527343866, total steps: 15726
episode:258, reward: -332.3235091468953, mean reward: -332.32, score: -332.3235091468953, epsilon: 0.5532244783055374, total steps: 15727
episode:259, reward: -13.18965607231145, mean reward: -2.13, score: -204.06856196063114, epsilon: 0.5516167337382093, total steps: 15823
episode:260, reward: -7.002541173524481, mean reward: -2.64, score: -200.52066205522908, epsilon: 0.5503475796200511, total steps: 15899
episode:261, reward: -15.957068225455332, mean reward: -1.37, score: -213.43244854959778, epsilon: 0.5477525251950518, total steps: 16055
episode:262, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.5477359337207381, total steps: 16056
episode:263, reward: -11.697143530665741, mean reward: -2.64, score: -200.8990273804306, epsilon: 0.5464765985200775, total steps: 16132
episode:264, reward: -15.786402414162641, mean reward: -1.42, score: -214.7292146170023, epsilon: 0.5439839447486822, total steps: 16283
episode:265, reward: -6.323725565652122, mean reward: -3.54, score: -201.6966614222577, epsilon: 0.543046266330242, total steps: 16340
episode:266, reward: -11.454659123909146, mean reward: -0.94, score: -201.86421862561153, epsilon: 0.5395253995969589, total steps: 16555
episode:267, reward: -426.28352744411956, mean reward: -426.28, score: -426.28352744411956, epsilon: 0.5395090823555946, total steps: 16556
episode:268, reward: -14.410506521862605, mean reward: -1.76, score: -207.30554622961222, epsilon: 0.5375874616298898, total steps: 16674
episode:269, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.537571208985381, total steps: 16675
episode:270, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.5375549568826181, total steps: 16676
episode:271, reward: -332.3172439885726, mean reward: -332.32, score: -332.3172439885726, epsilon: 0.5375387053215829, total steps: 16677
episode:272, reward: -7.918631253194429, mean reward: -1.54, score: -206.59183441890772, epsilon: 0.5353658886741667, total steps: 16811
episode:273, reward: -18.327758708665964, mean reward: -2.15, score: -210.6288846871894, epsilon: 0.533782946983571, total steps: 16909
episode:274, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.5337668211541036, total steps: 16910
episode:275, reward: -14.410991483822876, mean reward: -1.61, score: -212.32853392100594, epsilon: 0.5316429231432039, total steps: 17042
episode:276, reward: -9.644815361924863, mean reward: -2.95, score: -203.37201641159157, epsilon: 0.530536417389376, total steps: 17111
episode:277, reward: -9.842726385470566, mean reward: -1.74, score: -200.66935259332402, epsilon: 0.5286978872235489, total steps: 17226
episode:278, reward: -11.501418578642037, mean reward: -1.95, score: -201.15022210844904, epsilon: 0.5270571759767496, total steps: 17329
episode:279, reward: -11.375476745752698, mean reward: -4.01, score: -200.57606108973744, epsilon: 0.5262627428949198, total steps: 17379
episode:280, reward: -1.018341918808828, mean reward: -1.94, score: -200.13997198169824, epsilon: 0.5246303779742569, total steps: 17482
episode:281, reward: -7.2218391373355315, mean reward: -4.6, score: -206.88292179717484, epsilon: 0.5239189660995913, total steps: 17527
episode:282, reward: -23.858492249035436, mean reward: -1.74, score: -203.9681498501495, epsilon: 0.522074281604705, total steps: 17644
episode:283, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.5220585460575787, total steps: 17645
episode:284, reward: -7.836795146475279, mean reward: -1.28, score: -203.4055376298861, epsilon: 0.5195632541281463, total steps: 17804
episode:285, reward: -425.6229276310202, mean reward: -425.62, score: -425.6229276310202, epsilon: 0.519547602280541, total steps: 17805
episode:286, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.5195319509546551, total steps: 17806
episode:287, reward: -4.188082302674575, mean reward: -1.41, score: -200.80149769053614, epsilon: 0.517314751232405, total steps: 17948
episode:288, reward: -426.05545881221707, mean reward: -426.06, score: -426.05545881221707, epsilon: 0.517299174333647, total steps: 17949
episode:289, reward: -11.18042020389711, mean reward: -2.03, score: -208.6900997224862, epsilon: 0.5156975315618434, total steps: 18052
episode:290, reward: -12.087583377203323, mean reward: -2.59, score: -202.28250117377289, epsilon: 0.5144882906741424, total steps: 18130
episode:291, reward: -10.304700720464293, mean reward: -4.28, score: -205.40539582643638, epsilon: 0.5137457036371119, total steps: 18178
episode:292, reward: -6.245254589038639, mean reward: -1.52, score: -205.43518816691247, epsilon: 0.5116635363607728, total steps: 18313
episode:293, reward: -336.5728055929083, mean reward: -336.57, score: -336.5728055929083, epsilon: 0.5116481478327042, total steps: 18314
episode:294, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.5116327598175782, total steps: 18315
episode:295, reward: -14.888957818621378, mean reward: -1.4, score: -207.14606810809275, epsilon: 0.5093609798671935, total steps: 18463
episode:296, reward: -20.4837265458339, mean reward: -1.65, score: -207.8888714301616, epsilon: 0.5074357096493551, total steps: 18589
episode:297, reward: -15.495375288536385, mean reward: -1.18, score: -210.21225111074853, epsilon: 0.5047296270892038, total steps: 18767
episode:298, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.5047144696875923, total steps: 18768
episode:299, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.504699312791219, total steps: 18769
episode:300, reward: -19.2826112924175, mean reward: -1.49, score: -201.5482651969921, epsilon: 0.5026577628162168, total steps: 18904
episode:301, reward: -23.582096585642024, mean reward: -1.2, score: -221.89096834179503, epsilon: 0.49987496239877455, total steps: 19089
episode:302, reward: -12.203029493141173, mean reward: -2.33, score: -211.98075060593942, epsilon: 0.4985124092631707, total steps: 19180
episode:303, reward: -7.44017482914325, mean reward: -1.29, score: -200.06385477751937, epsilon: 0.49620107124684126, total steps: 19335
episode:304, reward: -3.9541195520910217, mean reward: -2.09, score: -200.21007502616393, epsilon: 0.49477550993343156, total steps: 19431
episode:305, reward: -417.5645148134928, mean reward: -417.56, score: -417.5645148134928, epsilon: 0.49476068433019516, total steps: 19432
episode:306, reward: -16.058293071229848, mean reward: -3.45, score: -206.77204682329403, epsilon: 0.4938720518901856, total steps: 19492
episode:307, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.4938572564017154, total steps: 19493
episode:308, reward: -7.86963964869985, mean reward: -1.32, score: -200.94686865986046, epsilon: 0.4916140671807344, total steps: 19645
episode:309, reward: -425.86694258034896, mean reward: -425.87, score: -425.86694258034896, epsilon: 0.49159934695716684, total steps: 19646
episode:310, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.49158462722426527, total steps: 19647
episode:311, reward: -16.335610415276854, mean reward: -1.46, score: -204.85743335065246, epsilon: 0.48952869985886405, total steps: 19787
episode:312, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.48951404914638197, total steps: 19788
episode:313, reward: -26.362786175400966, mean reward: -0.91, score: -216.29900399278245, epsilon: 0.48605556714898496, total steps: 20025
episode:314, reward: -332.481626191708, mean reward: -332.48, score: -332.481626191708, epsilon: 0.4860410322056638, total steps: 20026
episode:315, reward: -26.45243800421425, mean reward: -1.07, score: -203.62144593514785, epsilon: 0.4832881656142727, total steps: 20216
episode:316, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.48327372291613185, total steps: 20217
episode:317, reward: -27.323560849331496, mean reward: -2.3, score: -225.60668060464343, epsilon: 0.4818606713287674, total steps: 20315
episode:318, reward: -417.3078628387023, mean reward: -417.31, score: -417.3078628387023, epsilon: 0.4818462762129764, total steps: 20316
episode:319, reward: -8.542668319428632, mean reward: -1.09, score: -201.122301380035, epsilon: 0.4792057250201619, total steps: 20500
episode:320, reward: -16.084914605837355, mean reward: -1.43, score: -210.1363528220242, epsilon: 0.477107761176654, total steps: 20647
episode:321, reward: -5.108665559205022, mean reward: -5.3, score: -201.4505542007346, epsilon: 0.4765671005032118, total steps: 20685
episode:322, reward: -4.2080161879346, mean reward: -0.99, score: -201.05493283017182, epsilon: 0.47369040691289616, total steps: 20888
episode:323, reward: -425.8769368828274, mean reward: -425.88, score: -425.8769368828274, epsilon: 0.47367628413471335, total steps: 20889
episode:324, reward: -14.522535396595408, mean reward: -0.97, score: -202.8253146819912, epsilon: 0.4707349303008344, total steps: 21098
episode:325, reward: -417.57752598538104, mean reward: -417.58, score: -417.57752598538104, epsilon: 0.47072090603689676, total steps: 21099
episode:326, reward: -9.612644042678879, mean reward: -1.11, score: -202.88065928842212, epsilon: 0.4681623201308287, total steps: 21282
episode:327, reward: -9.125356833516689, mean reward: -1.25, score: -200.4635158176982, epsilon: 0.46593805772885943, total steps: 21442
episode:328, reward: -17.25004525881077, mean reward: -1.42, score: -208.60410157125284, epsilon: 0.4639049464365693, total steps: 21589
episode:329, reward: -14.430951486050656, mean reward: -2.76, score: -201.6209952541907, epsilon: 0.4628990021288404, total steps: 21662
episode:330, reward: -7.129059296582143, mean reward: -2.1, score: -205.69762388158117, epsilon: 0.4615523993705368, total steps: 21760
episode:331, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.4615386811858621, total steps: 21761
episode:332, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.4615249634584527, total steps: 21762
episode:333, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.46151124618829314, total steps: 21763
episode:334, reward: -425.8952815643157, mean reward: -425.9, score: -425.8952815643157, epsilon: 0.46149752937536836, total steps: 21764
episode:335, reward: -1.0308659594763045, mean reward: -0.88, score: -200.80074421125576, epsilon: 0.4583956151119089, total steps: 21991
episode:336, reward: -14.844374027771135, mean reward: -4.01, score: -200.37852725604327, epsilon: 0.4577155226545323, total steps: 22041
episode:337, reward: -28.1926407826564, mean reward: -1.11, score: -216.1787537657531, epsilon: 0.4550739661165002, total steps: 22236
episode:338, reward: -332.48807543786216, mean reward: -332.49, score: -332.48807543786216, epsilon: 0.45506046387600163, total steps: 22237
episode:339, reward: -6.744689352431234, mean reward: -4.81, score: -206.74294735514616, epsilon: 0.4544802930994965, total steps: 22280
episode:340, reward: -6.83016979069622, mean reward: -1.39, score: -201.84228517248215, epsilon: 0.45253002196812336, total steps: 22425
episode:341, reward: -16.738600019925663, mean reward: -3.62, score: -202.6005870253345, epsilon: 0.4517793334543734, total steps: 22481
episode:342, reward: -6.197098899560822, mean reward: -4.18, score: -200.83725737712967, epsilon: 0.4511370005242215, total steps: 22529
episode:343, reward: -5.119107632752341, mean reward: -1.14, score: -203.68180693532963, epsilon: 0.44875067603546454, total steps: 22708
episode:344, reward: -332.2910031491348, mean reward: -332.29, score: -332.2910031491348, epsilon: 0.44873738456778905, total steps: 22709
episode:345, reward: -14.259365784088988, mean reward: -2.14, score: -209.53856367308362, epsilon: 0.4474369676156304, total steps: 22807
episode:346, reward: -12.724625973615392, mean reward: -1.26, score: -205.8635561720942, epsilon: 0.44528341587175707, total steps: 22970
episode:347, reward: -336.1926003487936, mean reward: -336.19, score: -336.1926003487936, epsilon: 0.44527023997749415, total steps: 22971
episode:348, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.44525706452242036, total steps: 22972
episode:349, reward: -9.056893371411933, mean reward: -1.39, score: -204.65924735768775, epsilon: 0.4433250422265385, total steps: 23119
episode:350, reward: -332.32367870138046, mean reward: -332.32, score: -332.32367870138046, epsilon: 0.44331193161030913, total steps: 23120
episode:351, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.4432988214310929, total steps: 23121
episode:352, reward: -332.6188490981548, mean reward: -332.62, score: -332.6188490981548, epsilon: 0.4432857116888755, total steps: 23122
episode:353, reward: -6.403132007060595, mean reward: -3.3, score: -204.8900000868348, epsilon: 0.44247376052325077, total steps: 23184
episode:354, reward: -22.642458566364475, mean reward: -1.23, score: -213.65621876367962, epsilon: 0.440204001376629, total steps: 23358
episode:355, reward: -9.875061313577204, mean reward: -2.99, score: -200.6205494062962, epsilon: 0.4393335181749444, total steps: 23425
episode:356, reward: -6.870421947320861, mean reward: -4.66, score: -200.46906149739422, epsilon: 0.4387758732065919, total steps: 23468
episode:357, reward: -9.859481043954064, mean reward: -2.45, score: -203.56266245964022, epsilon: 0.4377017465177933, total steps: 23551
episode:358, reward: -6.626828627003486, mean reward: -1.35, score: -202.66939636974382, epsilon: 0.43576807599000245, total steps: 23701
episode:359, reward: -12.220347403564258, mean reward: -1.91, score: -200.50923450993034, epsilon: 0.43442024779927885, total steps: 23806
episode:360, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.4344074340045833, total steps: 23807
episode:361, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.4343946206370072, total steps: 23808
episode:362, reward: -29.247497600386843, mean reward: -1.12, score: -217.61893777404086, epsilon: 0.4319168887245024, total steps: 24002
episode:363, reward: -417.05776380562236, mean reward: -417.06, score: -417.05776380562236, epsilon: 0.43190415837371865, total steps: 24003
episode:364, reward: -13.386590250348878, mean reward: -1.93, score: -211.80025269155337, epsilon: 0.4305064072360993, total steps: 24113
episode:365, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.4304937239005815, total steps: 24114
episode:366, reward: -417.33517258528826, mean reward: -417.34, score: -417.33517258528826, epsilon: 0.4304810409878346, total steps: 24115
episode:367, reward: -16.662103196761088, mean reward: -2.05, score: -215.0801305088252, epsilon: 0.4291516850742764, total steps: 24220
episode:368, reward: -4.456935597137188, mean reward: -6.31, score: -202.007191983939, epsilon: 0.4287474722287068, total steps: 24252
episode:369, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.42873484752337876, total steps: 24253
episode:370, reward: -6.546167972349885, mean reward: -1.98, score: -203.71751058081517, epsilon: 0.42743675421552974, total steps: 24356
episode:371, reward: -13.551434141535482, mean reward: -2.12, score: -203.5725483143374, epsilon: 0.42623088701856165, total steps: 24452
episode:372, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.4262183461980092, total steps: 24453
episode:373, reward: -23.217640632922574, mean reward: -1.74, score: -213.66072588362314, epsilon: 0.4246790087766657, total steps: 24576
episode:374, reward: -332.4771562705121, mean reward: -332.48, score: -332.4771562705121, epsilon: 0.42466651968452584, total steps: 24577
episode:375, reward: -11.03701037938795, mean reward: -1.72, score: -208.40696670870312, epsilon: 0.42315840812457883, total steps: 24698
episode:376, reward: -15.911397727874215, mean reward: -3.34, score: -210.135810587244, epsilon: 0.4223755977061394, total steps: 24761
episode:377, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.4223631853930889, total steps: 24762
episode:378, reward: -336.7264286750148, mean reward: -336.73, score: -336.7264286750148, epsilon: 0.4223507734937753, total steps: 24763
episode:379, reward: -6.513480278147794, mean reward: -1.37, score: -203.17755475142232, epsilon: 0.4205183666644427, total steps: 24911
episode:380, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.42050601625806183, total steps: 24912
episode:381, reward: -11.328483105270543, mean reward: -0.93, score: -203.9113339449607, epsilon: 0.4177989103257554, total steps: 25132
episode:382, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.4177866505664083, total steps: 25133
episode:383, reward: -17.190831844247054, mean reward: -1.47, score: -210.4315410270683, epsilon: 0.41603770582849653, total steps: 25276
episode:384, reward: -10.633939618651956, mean reward: -3.45, score: -203.65284486926507, epsilon: 0.41531853908612854, total steps: 25335
episode:385, reward: -4.968748130396087, mean reward: -2.12, score: -201.29970543729374, epsilon: 0.414163526780357, total steps: 25430
episode:386, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.4141513881984418, total steps: 25431
episode:387, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.41413925002113927, total steps: 25432
episode:388, reward: -16.041411748706935, mean reward: -2.21, score: -208.1662461859678, epsilon: 0.41300006602468864, total steps: 25526
episode:389, reward: -6.045184702453228, mean reward: -3.15, score: -201.6006066485525, epsilon: 0.41222649132356914, total steps: 25590
episode:390, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.4122144173084264, total steps: 25591
episode:391, reward: -336.5962306648572, mean reward: -336.6, score: -336.5962306648572, epsilon: 0.41220234369574416, total steps: 25592
episode:392, reward: -18.11862277130937, mean reward: -0.93, score: -202.8897073418362, epsilon: 0.40959186601918957, total steps: 25809
episode:393, reward: -5.963720024345927, mean reward: -2.03, score: -205.2834287551406, epsilon: 0.4083832756722338, total steps: 25910
episode:394, reward: -7.7436930289835155, mean reward: -5.74, score: -206.47735303930745, epsilon: 0.40795347367420215, total steps: 25946
episode:395, reward: -1.7144276572990373, mean reward: -2.63, score: -200.07250703533416, epsilon: 0.4070478058711426, total steps: 26022
episode:396, reward: -25.7732704639202, mean reward: -1.66, score: -204.74962290547631, epsilon: 0.4055869067567311, total steps: 26145
episode:397, reward: -417.4037384287685, mean reward: -417.4, score: -417.4037384287685, epsilon: 0.4055750540573852, total steps: 26146
episode:398, reward: -18.703370689320845, mean reward: -1.18, score: -211.59731783503693, epsilon: 0.40344799130249004, total steps: 26326
episode:399, reward: -12.39737685610328, mean reward: -3.4, score: -207.20376445248286, epsilon: 0.40273004388074657, total steps: 26387
episode:400, reward: -2.9326447952140793, mean reward: -3.11, score: -202.45704562918576, epsilon: 0.4019666227905058, total steps: 26452
episode:401, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.40195489076528096, total steps: 26453
episode:402, reward: -12.703710994152765, mean reward: -2.44, score: -200.25740738181057, epsilon: 0.40099419428050753, total steps: 26535
episode:403, reward: -15.16337374984468, mean reward: -2.61, score: -211.68853334781215, epsilon: 0.4000477881791286, total steps: 26616
episode:404, reward: -3.1649675689555146, mean reward: -1.3, score: -201.110120352101, epsilon: 0.3982438720696956, total steps: 26771
episode:405, reward: -8.44136372061699, mean reward: -1.72, score: -203.2338007860705, epsilon: 0.3968768031708949, total steps: 26889
episode:406, reward: -3.4653142757762727, mean reward: -4.78, score: -200.76176492361373, epsilon: 0.39639151542713996, total steps: 26931
episode:407, reward: -6.405668276407097, mean reward: -1.43, score: -202.29787032682898, epsilon: 0.39476729521205545, total steps: 27072
episode:408, reward: -24.63774961503031, mean reward: -1.47, score: -213.17640981524752, epsilon: 0.3931049405451785, total steps: 27217
episode:409, reward: -6.869222807960931, mean reward: -2.54, score: -206.09096228172416, epsilon: 0.39217980669841834, total steps: 27298
episode:410, reward: -16.845175063631686, mean reward: -1.01, score: -203.51331655460552, epsilon: 0.38988353545548, total steps: 27500
episode:411, reward: -20.668991572564035, mean reward: -0.78, score: -201.65837427387098, epsilon: 0.3869506058676899, total steps: 27760
episode:412, reward: -426.02934128879934, mean reward: -426.03, score: -426.02934128879934, epsilon: 0.3869393743680204, total steps: 27761
episode:413, reward: -18.0716698151204, mean reward: -2.26, score: -214.4174461875664, epsilon: 0.385874087277287, total steps: 27856
episode:414, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.38586289166097243, total steps: 27857
episode:415, reward: -10.142229793374355, mean reward: -0.72, score: -209.05876012812288, epsilon: 0.38264294677367894, total steps: 28146
episode:416, reward: -417.42131999228684, mean reward: -417.42, score: -417.42131999228684, epsilon: 0.3826318588602527, total steps: 28147
episode:417, reward: -10.527042811148233, mean reward: -3.23, score: -206.4238500761666, epsilon: 0.38192300061232304, total steps: 28211
episode:418, reward: -11.536279050184412, mean reward: -1.16, score: -205.77157081347812, epsilon: 0.37995942185289777, total steps: 28389
episode:419, reward: -23.727441792268614, mean reward: -1.17, score: -218.5680392049675, epsilon: 0.37790907168679616, total steps: 28576
episode:420, reward: -336.5980465067617, mean reward: -336.6, score: -336.5980465067617, epsilon: 0.3778981415665763, total steps: 28577
episode:421, reward: -14.026892162352702, mean reward: -2.14, score: -202.89389910510272, epsilon: 0.37686143976245645, total steps: 28672
episode:422, reward: -6.525578217116865, mean reward: -0.65, score: -200.9780302677124, epsilon: 0.37352282983715396, total steps: 28980
episode:423, reward: -417.09308577814767, mean reward: -417.09, score: -417.09308577814767, epsilon: 0.373512045922559, total steps: 28981
episode:424, reward: -4.0158086064662415, mean reward: -1.49, score: -202.5451646239952, epsilon: 0.3720487772293968, total steps: 29117
episode:425, reward: -2.288195594155795, mean reward: -6.28, score: -201.03005155196914, epsilon: 0.37170544167853253, total steps: 29149
episode:426, reward: -8.201476956659471, mean reward: -1.31, score: -202.44082949069323, epsilon: 0.3700475833850837, total steps: 29304
episode:427, reward: -4.715140348685546, mean reward: -5.23, score: -203.80190106100778, epsilon: 0.3696317918497384, total steps: 29343
episode:428, reward: -17.230983597077678, mean reward: -1.25, score: -210.57517007255635, epsilon: 0.3678468562995495, total steps: 29511
episode:429, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.36783626158091914, total steps: 29512
episode:430, reward: -13.706403999589888, mean reward: -2.68, score: -208.90490441850685, epsilon: 0.36701096065692945, total steps: 29590
episode:431, reward: -28.132592953963183, mean reward: -0.93, score: -201.8799562564914, epsilon: 0.36471569723326197, total steps: 29808
episode:432, reward: -332.15372949432793, mean reward: -332.15, score: -332.15372949432793, epsilon: 0.36470520688486097, total steps: 29809
episode:433, reward: -13.657050688161268, mean reward: -2.01, score: -212.58422663869075, epsilon: 0.3635952106353822, total steps: 29915
episode:434, reward: -12.731986344342351, mean reward: -9.49, score: -208.75885958674638, epsilon: 0.363365325115909, total steps: 29937
episode:435, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.3633548797791617, total steps: 29938
episode:436, reward: -336.60483222206284, mean reward: -336.6, score: -336.60483222206284, epsilon: 0.36334443479058653, total steps: 29939
episode:437, reward: -9.726839725463115, mean reward: -5.01, score: -205.3196160015544, epsilon: 0.3629164898919956, total steps: 29980
episode:438, reward: -26.487774025589246, mean reward: -1.01, score: -203.19868925933775, epsilon: 0.36082695716095603, total steps: 30181
episode:439, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.36081659643506375, total steps: 30182
episode:440, reward: -18.08139049356855, mean reward: -2.04, score: -210.44665091947746, epsilon: 0.3597512892777236, total steps: 30285
episode:441, reward: -7.231083774845556, mean reward: -1.97, score: -200.71198477301775, epsilon: 0.3586999232292775, total steps: 30387
episode:442, reward: -5.240286491408527, mean reward: -1.32, score: -202.84165177421272, epsilon: 0.35711932396568774, total steps: 30541
episode:443, reward: -417.40494231271765, mean reward: -417.4, score: -417.40494231271765, epsilon: 0.35710908682550885, total steps: 30542
episode:444, reward: -5.101611196147563, mean reward: -0.9, score: -204.26716464915188, epsilon: 0.35480422425405816, total steps: 30768
episode:445, reward: -10.30137780833247, mean reward: -6.93, score: -207.9371374132687, epsilon: 0.3544995723811282, total steps: 30798
episode:446, reward: -10.983560591300172, mean reward: -1.09, score: -203.08837886228417, epsilon: 0.352607428355346, total steps: 30985
episode:447, reward: -426.2932621921543, mean reward: -426.29, score: -426.2932621921543, epsilon: 0.3525973416091809, total steps: 30986
episode:448, reward: -10.252116563839156, mean reward: -2.41, score: -204.7817246717508, epsilon: 0.3517411959204261, total steps: 31071
episode:449, reward: -100, mean reward: -5.46, score: -152.96016283685253, epsilon: 0.35145970218840966, total steps: 31099
episode:450, reward: -17.584263829105403, mean reward: -1.1, score: -204.08115469714676, epsilon: 0.3496064208487224, total steps: 31284
episode:451, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.3495964341344736, total steps: 31285
episode:452, reward: -8.809595426435072, mean reward: -0.86, score: -204.9181510364711, epsilon: 0.3472191313720363, total steps: 31524
episode:453, reward: -8.958467700749502, mean reward: -6.15, score: -202.85721243052072, epsilon: 0.34689237007918655, total steps: 31557
episode:454, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.34688247383178894, total steps: 31558
episode:455, reward: -417.42075822293754, mean reward: -417.42, score: -417.42075822293754, epsilon: 0.3468725779142608, total steps: 31559
episode:456, reward: -7.30465149696844, mean reward: -1.31, score: -205.45803316063015, epsilon: 0.34532300301411434, total steps: 31716
episode:457, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.3453131590780804, total steps: 31717
episode:458, reward: -2.7537191366784284, mean reward: -1.65, score: -202.39065501370138, epsilon: 0.3441048538442234, total steps: 31840
episode:459, reward: -417.42145594523913, mean reward: -417.42, score: -417.42145594523913, epsilon: 0.34409505051248507, total steps: 31841
episode:460, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.34408524750751895, total steps: 31842
episode:461, reward: -336.5831450479941, mean reward: -336.58, score: -336.5831450479941, epsilon: 0.34407544482931424, total steps: 31843
episode:462, reward: -100, mean reward: -10.16, score: -223.46319453362622, epsilon: 0.3438598685574001, total steps: 31865
episode:463, reward: -13.07951215940535, mean reward: -2.47, score: -207.8446388111231, epsilon: 0.34303821178174104, total steps: 31949
episode:464, reward: -11.278522884982038, mean reward: -6.46, score: -206.67190020797415, epsilon: 0.342725804336099, total steps: 31981
episode:465, reward: -7.199304751149292, mean reward: -1.42, score: -204.14533263623773, epsilon: 0.3413240872874981, total steps: 32125
episode:466, reward: -5.560151090744198, mean reward: -5.62, score: -202.2074441500191, epsilon: 0.34097470805221974, total steps: 32161
episode:467, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.3409650090569355, total steps: 32162
episode:468, reward: -29.0904203263047, mean reward: -1.62, score: -219.91583138705641, epsilon: 0.3396489529968141, total steps: 32298
episode:469, reward: -19.262690512245506, mean reward: -1.26, score: -202.09414781066317, epsilon: 0.33810827071889143, total steps: 32458
episode:470, reward: -417.55041140018506, mean reward: -417.55, score: -417.55041140018506, epsilon: 0.3380986672699258, total steps: 32459
episode:471, reward: -4.894377653561014, mean reward: -0.79, score: -201.6998099728708, epsilon: 0.3356602067369434, total steps: 32714
episode:472, reward: -426.28882336915945, mean reward: -426.29, score: -426.28882336915945, epsilon: 0.33565068488875055, total steps: 32715
episode:473, reward: -10.763525012499505, mean reward: -1.83, score: -200.99924839147448, epsilon: 0.33460521690676986, total steps: 32825
episode:474, reward: -18.783538443650198, mean reward: -1.98, score: -201.5292226161421, epsilon: 0.3336392023246703, total steps: 32927
episode:475, reward: -15.756596619262874, mean reward: -1.78, score: -200.97260692843912, epsilon: 0.33257283757696743, total steps: 33040
episode:476, reward: -21.06213811011459, mean reward: -1.24, score: -211.0717446084269, epsilon: 0.3309761198037516, total steps: 33210
episode:477, reward: -6.432865100414849, mean reward: -1.2, score: -204.74307976845859, epsilon: 0.3293791117178122, total steps: 33381
episode:478, reward: -336.5463277102819, mean reward: -336.55, score: -336.5463277102819, epsilon: 0.3293697992359638, total steps: 33382
episode:479, reward: -7.337808795267786, mean reward: -1.98, score: -204.11389142384473, epsilon: 0.32841227428367914, total steps: 33485
episode:480, reward: -5.094880072217714, mean reward: -1.07, score: -203.96720797601267, epsilon: 0.3266453468249313, total steps: 33676
episode:481, reward: -25.32216581503844, mean reward: -3.06, score: -207.77640108960955, epsilon: 0.326018994173305, total steps: 33744
episode:482, reward: -21.94208837450992, mean reward: -1.36, score: -218.02952984873684, epsilon: 0.3245508115049646, total steps: 33904
episode:483, reward: -2.5073136030910503, mean reward: -8.8, score: -202.3705907522756, epsilon: 0.3243404032162943, total steps: 33927
episode:484, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.32433125868859675, total steps: 33928
episode:485, reward: -332.47175294252287, mean reward: -332.47, score: -332.47175294252287, epsilon: 0.32432211446571163, total steps: 33929
episode:486, reward: -6.899447284133478, mean reward: -7.31, score: -204.5754275626295, epsilon: 0.32406619993756763, total steps: 33957
episode:487, reward: -6.938176217906173, mean reward: -2.11, score: -200.23949392487646, epsilon: 0.3231996963259091, total steps: 34052
episode:488, reward: -100, mean reward: -0.03, score: -2.3007822137926723, epsilon: 0.3225448032407778, total steps: 34124
episode:489, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.3225357185654152, total steps: 34125
episode:490, reward: -7.195256781569257, mean reward: -1.52, score: -205.06507060320612, epsilon: 0.32131206312153743, total steps: 34260
episode:491, reward: -425.87322020993304, mean reward: -425.87, score: -425.87322020993304, epsilon: 0.3213030195368273, total steps: 34261
episode:492, reward: -17.800595439348747, mean reward: -0.88, score: -206.12087239965697, epsilon: 0.31918611458613794, total steps: 34496
episode:493, reward: -417.0952635408283, mean reward: -417.1, score: -417.0952635408283, epsilon: 0.3191771418651979, total steps: 34497
episode:494, reward: -12.680901488234658, mean reward: -1.65, score: -201.5580385049606, epsilon: 0.3180847109366986, total steps: 34619
episode:495, reward: -6.150400065837999, mean reward: -1.46, score: -201.3463568625457, epsilon: 0.31685435325857936, total steps: 34757
episode:496, reward: -7.877548480085933, mean reward: -3.82, score: -202.27505387651652, epsilon: 0.3163833267637368, total steps: 34810
episode:497, reward: -15.16296194023304, mean reward: -1.31, score: -213.4440140210808, epsilon: 0.3149399022093164, total steps: 34973
episode:498, reward: -28.049541224891296, mean reward: -1.08, score: -208.56324806546755, epsilon: 0.3132409264036766, total steps: 35166
episode:499, reward: -331.97286825450976, mean reward: -331.97, score: -331.97286825450976, epsilon: 0.3132321518523732, total steps: 35167
episode:500, reward: -15.517941601992154, mean reward: -1.71, score: -208.8542636808233, epsilon: 0.3121638481247002, total steps: 35289
episode:501, reward: -417.9128938743152, mean reward: -417.91, score: -417.9128938743152, epsilon: 0.3121551094754077, total steps: 35290
episode:502, reward: -48.60739921172931, mean reward: -0.77, score: -215.90939835962683, epsilon: 0.30970239725389104, total steps: 35572
episode:503, reward: -100, mean reward: -5.0, score: -114.88909485109184, epsilon: 0.3095033683868108, total steps: 35595
episode:504, reward: -100, mean reward: -3.52, score: -63.41594740870275, epsilon: 0.3093477130670443, total steps: 35613
episode:505, reward: 0.4084089479499882, mean reward: 10.33, score: 4142.9853278239025, epsilon: 0.30590416429081724, total steps: 36014
episode:506, reward: -426.4082626141739, mean reward: -426.41, score: -426.4082626141739, epsilon: 0.30589563429417493, total steps: 36015
episode:507, reward: -3.0986445412362174, mean reward: -1.45, score: -201.27241015871084, epsilon: 0.3047127270399493, total steps: 36154
episode:508, reward: 0.3549001761415811, mean reward: 8.19, score: 3285.095369152755, epsilon: 0.30133072035434905, total steps: 36555
episode:509, reward: -332.4878595765274, mean reward: -332.49, score: -332.4878595765274, epsilon: 0.30132234280329717, total steps: 36556
episode:510, reward: -8.052738295977724, mean reward: -0.75, score: -202.2546135877615, epsilon: 0.2990788922972358, total steps: 36825
episode:511, reward: -425.88387619649194, mean reward: -425.88, score: -425.88387619649194, epsilon: 0.29907058980586815, total steps: 36826
episode:512, reward: -9.817404472026572, mean reward: -1.91, score: -206.4411246051382, epsilon: 0.29817554772495786, total steps: 36934
episode:513, reward: -4.757801110213231, mean reward: -1.18, score: -201.70903762241787, epsilon: 0.2967649710655393, total steps: 37105
episode:514, reward: -100, mean reward: -1.25, score: -149.5066461330505, epsilon: 0.295779882671516, total steps: 37225
episode:515, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.29577169014530313, total steps: 37226
episode:516, reward: -9.868821836965958, mean reward: -1.48, score: -204.06900609945365, epsilon: 0.29464373665262517, total steps: 37364
episode:517, reward: -7.09891365932675, mean reward: -1.78, score: -202.54087096091925, epsilon: 0.29371585454589916, total steps: 37478
episode:518, reward: -100, mean reward: 1.22, score: 199.2629561328867, epsilon: 0.29238717623732446, total steps: 37642
episode:519, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.2923790967994413, total steps: 37643
episode:520, reward: -7.79695441536788, mean reward: -0.87, score: -202.58289254063604, epsilon: 0.2904958938836065, total steps: 37877
episode:521, reward: -10.92937547417217, mean reward: -3.31, score: -208.38597804082704, epsilon: 0.28999138242888634, total steps: 37940
episode:522, reward: -100, mean reward: -100.0, score: -100, epsilon: 0.2899833828494658, total steps: 37941
